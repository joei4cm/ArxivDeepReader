{
  "papers": {
    "2412.19255": {
      "title": "解锁LLM效率：KV缓存优化技术深度解析 - Multi-matrix Factorization Attention: Breaking the KV Cache Bottleneck in LLMs",
      "description": "大型语言模型（LLM）的推理性能长期受限于一个核心瓶颈：键值（KV）缓存。本报告将深入探讨以多矩阵分解注意力（MFA）为代表的架构创新，如何从根本上解决这一挑战，推动AI进入一个更高效、更普及的新时代。",
      "category": "KV缓存优化",
      "categoryColor": "blue",
      "tags": [
        "架构创新",
        "内存优化",
        "性能提升"
      ],
      "tagColors": [
        "purple",
        "green",
        "orange"
      ],
      "gradient": "from-blue-600 to-purple-600",
      "folder": "2412.19255v2",
      "files": [
        {
          "name": "2412.19255v2.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "2412.19255v2.pdf",
          "type": "original",
          "priority": 2,
          "icon": "📄",
          "label": "原文PDF"
        },
        {
          "name": "LLM 缓存优化研究报告_.pdf",
          "type": "report",
          "priority": 2,
          "icon": "📊",
          "label": "研究报告"
        },
        {
          "name": "Step3-Application\\Step3-Model-Analysis.html",
          "type": "model_analysis",
          "priority": 2,
          "icon": "🧠",
          "label": "模型分析"
        },
        {
          "name": "Step3-Application\\Step3-Sys-Model.pdf",
          "type": "sys_model",
          "priority": 3,
          "icon": "⚙️",
          "label": "系统模型"
        },
        {
          "name": "Step3-Application\\Step3-MFA_MFA-KR解析.pdf",
          "type": "mfa_analysis",
          "priority": 3,
          "icon": "🔍",
          "label": "MFA-KR解析"
        }
      ]
    },
    "2507.11851": {
      "title": "信息图：揭示LLM的多令牌预测潜力",
      "description": "深入探讨 arXiv:2507.11851 论文，揭示大型语言模型（LLM）如何通过一次预测多个令牌来彻底改变推理速度。",
      "category": "推理加速",
      "categoryColor": "emerald",
      "tags": [
        "并行计算",
        "推测解码",
        "效率优化"
      ],
      "tagColors": [
        "blue",
        "red",
        "yellow"
      ],
      "gradient": "from-emerald-600 to-teal-600",
      "folder": "2507.11851v1",
      "files": [
        {
          "name": "2507.11851v1.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "2507.11851v1.pdf",
          "type": "original",
          "priority": 2,
          "icon": "📄",
          "label": "原文PDF"
        },
        {
          "name": "论文分析：原理、创新与应用_.pdf",
          "type": "analysis_pdf",
          "priority": 2,
          "icon": "📊",
          "label": "分析报告"
        }
      ]
    },
    "2405.16444": {
      "title": "CacheBlend: A Visual Deep Dive into High-Performance RAG",
      "description": "A visual deep dive into the technology that makes Retrieval-Augmented Generation fast, efficient, and commercially viable.",
      "category": "KV缓存优化",
      "categoryColor": "blue",
      "tags": [
        "架构创新",
        "内存优化",
        "性能提升"
      ],
      "tagColors": [
        "purple",
        "green",
        "orange"
      ],
      "gradient": "from-blue-600 to-purple-600",
      "folder": "2405.16444v3",
      "files": [
        {
          "name": "2405.1644v3_en.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "2405.1644v3_cn.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "2405.16444v3.pdf",
          "type": "original",
          "priority": 2,
          "icon": "📄",
          "label": "原文PDF"
        },
        {
          "name": "深度解读CacheBlend：破解RAG推理瓶颈的缓存新策略.pdf",
          "type": "document",
          "priority": 3,
          "icon": "📄",
          "label": "PDF文档"
        }
      ]
    },
    "1706.03762": {
      "title": "解构革命: 'Attention Is All You Need' 可视化指南 (含MoE)",
      "description": "在Transformer横空出世前，语言模型的世界由循环神经网络（RNN）主导。它们像一个逐字阅读的读者，但存在两个致命缺陷：容易“遗忘”长距离信息，且天生的“串行”处理机制严重拖慢了训练速度，成为了AI发展的瓶颈。",
      "category": "KV缓存优化",
      "categoryColor": "blue",
      "tags": [
        "架构创新",
        "内存优化",
        "性能提升"
      ],
      "tagColors": [
        "purple",
        "green",
        "orange"
      ],
      "gradient": "from-blue-600 to-purple-600",
      "folder": "1706.03762v7",
      "files": [
        {
          "name": "1706.03762v7.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "Transformer论文分析与LLM入门指南_.pdf",
          "type": "analysis_pdf",
          "priority": 2,
          "icon": "📊",
          "label": "分析报告"
        },
        {
          "name": "1706.03762v7.pdf",
          "type": "document",
          "priority": 3,
          "icon": "📄",
          "label": "PDF文档"
        }
      ]
    },
    "2403.03206": {
      "title": "Stable Diffusion 3 架构解析",
      "description": "一份详细介绍 Stable Diffusion 3 背后技术：多模态扩散变换器 (MMDiT) 的信息图。",
      "category": "图像生成",
      "categoryColor": "pink",
      "tags": [
        "扩散模型",
        "多模态",
        "图像生成"
      ],
      "tagColors": [
        "pink",
        "indigo",
        "cyan"
      ],
      "gradient": "from-pink-600 to-rose-600",
      "folder": "2403.03206v1",
      "files": [
        {
          "name": "2403.03206v1.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "2403.03206v1.pdf",
          "type": "original",
          "priority": 2,
          "icon": "📄",
          "label": "原文PDF"
        },
        {
          "name": "论文解读：自知识增强模型_.pdf",
          "type": "document",
          "priority": 3,
          "icon": "📄",
          "label": "PDF文档"
        }
      ]
    },
    "2505.09388": {
      "title": "Qwen3技术报告：信息图表",
      "description": "Qwen3提供从轻量级边缘设备到强大云服务器的全方位模型，涵盖密集型（Dense）和高效的混合专家（MoE）架构。",
      "category": "模型训练",
      "categoryColor": "purple",
      "tags": [
        "训练优化",
        "参数高效",
        "微调技术"
      ],
      "tagColors": [
        "blue",
        "green",
        "purple"
      ],
      "gradient": "from-purple-600 to-indigo-600",
      "folder": "2505.09388v1",
      "files": [
        {
          "name": "2505.09388v1.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "2505.09388v1.pdf",
          "type": "original",
          "priority": 2,
          "icon": "📄",
          "label": "原文PDF"
        },
        {
          "name": "论文分析：Qwen3模型规格与变种_.pdf",
          "type": "analysis_pdf",
          "priority": 2,
          "icon": "📊",
          "label": "分析报告"
        }
      ]
    },
    "2106.09685": {
      "title": "AI之眼的演化 - 可变形注意力",
      "description": "探索AI如何学会停止关注一切，开始专注于重要的事物，甚至开始做梦。",
      "category": "计算机视觉",
      "categoryColor": "green",
      "tags": [
        "注意力机制",
        "计算机视觉",
        "可变形卷积"
      ],
      "tagColors": [
        "green",
        "blue",
        "teal"
      ],
      "gradient": "from-green-600 to-teal-600",
      "folder": "2106.09685v2",
      "files": [
        {
          "name": "2106.09685v2_cn.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析"
        },
        {
          "name": "2106.09685v2_en.html",
          "type": "analysis",
          "priority": 1,
          "icon": "📖",
          "label": "深度解析(EN)"
        },
        {
          "name": "2106.09685v2.pdf",
          "type": "original",
          "priority": 2,
          "icon": "📄",
          "label": "原文PDF"
        },
        {
          "name": "论文分析：Deformable Attention Transformer_.pdf",
          "type": "analysis_pdf",
          "priority": 2,
          "icon": "📊",
          "label": "分析报告"
        }
      ]
    }
  },
  "statistics": {
    "totalPapers": 7,
    "totalDocuments": 26
  },
  "lastUpdated": "2025-07-27T08:43:29.980253Z",
  "version": "1.0.0"
}