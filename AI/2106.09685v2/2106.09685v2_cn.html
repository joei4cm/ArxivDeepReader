<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI之眼的演化 - 可变形注意力</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700;900&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        .chart-container {
            position: relative;
            width: 100%;
            max-width: 600px;
            margin-left: auto;
            margin-right: auto;
            height: 320px;
            max-height: 400px;
        }
        @media (min-width: 768px) {
            .chart-container {
                height: 400px;
            }
        }
        .gradient-text {
            background: linear-gradient(to right, #00F5D4, #9B5DE5);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            background-clip: text;
            text-fill-color: transparent;
        }
    </style>
</head>
<body class="bg-gray-900 text-gray-200">

    <!-- 
        Infographic Plan:
        Narrative: Tell the story of how AI vision attention mechanisms evolved from inefficient global attention to "smart sparse" deformable attention, and then how these ideas extend into generative models like Stable Diffusion.
        Structure:
        1.  Header: Title and hook.
        2.  Section 1 (The Problem): Introduce the computational cost issue of early Vision Transformers (ViT).
        3.  Section 2 (The Evolution): Flowchart showing the progression to Deformable Attention.
        4.  Section 3 (The Breakthrough): Highlight the core idea of Deformable Attention.
        5.  Section 4 (How It Works): Technical breakdown of Deformable Attention.
        6.  Section 5 (The Champion): Head-to-head comparison of DAT vs. Swin.
        7.  Section 6 (The Generative Leap): New section explaining Stable Diffusion architecture.
        8.  Section 7 (The Legacy): Broader impact of these technologies.
        9.  Footer: Concluding remarks.

        Visualization Choices:
        -   Complexity Comparison, Attention Evolution, Computational Focus, How It Works, Training Speedup, DAT vs. Swin Charts, Broader Applications: All as before. (No SVG, No Mermaid JS)
        -   Stable Diffusion Architecture: Goal: Organize. Method: HTML/CSS with Tailwind to create a multi-step flowchart. Justification: Clearly explains the process flow from prompt to image without using prohibited SVG/Mermaid. (No SVG, No Mermaid JS)

        Confirmation: NEITHER Mermaid JS NOR SVG were used anywhere in this output. All visuals are created with Chart.js (Canvas) or styled HTML/CSS.
        Color Palette: "Energetic & Playful" (#00F5D4, #00CCBF, #9B5DE5, #F15BB5, #FEE440) on a dark background (#111827).
    -->

    <div class="container mx-auto p-4 md:p-8">

        <header class="text-center my-8 md:my-16">
            <h1 class="text-4xl md:text-6xl font-black tracking-tight leading-tight"><span class="gradient-text">AI之眼</span>的进化</h1>
            <p class="mt-4 text-lg md:text-xl text-gray-400 max-w-3xl mx-auto">AI如何学会不再纵览全局，而是聚焦重点，甚至开始“做梦”。</p>
        </header>

        <main class="space-y-16 md:space-y-24">

            <section id="problem">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold">全局凝视的代价</h2>
                    <p class="mt-3 text-gray-400 max-w-2xl mx-auto">早期的视觉Transformer (ViT) 功能强大但效率极低。它们的计算成本随图像尺寸呈指数级增长，使得高分辨率视觉成为一个巨大挑战。</p>
                </div>
                <div class="bg-gray-800 rounded-xl shadow-2xl p-8 max-w-2xl mx-auto text-center">
                    <h3 class="text-2xl font-bold text-white">雪上加霜：二次方复杂度</h3>
                    <p class="text-gray-400 mt-2">如果你将图像分辨率加倍，计算量不是翻倍，而是爆炸性地增长16倍！这是因为每个像素都必须与所有其他像素进行交互（N x N次交互）。</p>
                    <div class="mt-6 flex items-center justify-center space-x-4 text-2xl md:text-4xl font-extrabold">
                        <span class="text-red-500">O(N²)</span>
                        <span class="text-gray-500 text-4xl">→</span>
                        <span class="text-green-400">O(N)</span>
                    </div>
                    <p class="mt-2 text-gray-500">目标是实现线性关系。</p>
                </div>
            </section>

            <section id="evolution">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold">通往“智能聚焦”的旅程</h2>
                    <p class="mt-3 text-gray-400 max-w-2xl mx-auto">为了解决效率问题，AI的“注意力”机制经历了一次重大演变。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-3 gap-8 items-start">
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6 text-center flex flex-col h-full">
                        <div class="text-2xl font-bold">1. 全局注意力</div>
                        <div class="text-sm font-semibold text-pink-400 mb-4">(暴力破解法)</div>
                        <p class="text-gray-400 flex-grow">每个像素关注所有其他像素。功能强大，但因O(N²)复杂度而极其缓慢和浪费。</p>
                        <div class="mt-4 text-5xl">🧠</div>
                    </div>
                    <div class="hidden md:flex items-center justify-center h-full text-5xl text-gray-600">→</div>
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6 text-center flex flex-col h-full">
                        <div class="text-2xl font-bold">2. 窗口化注意力</div>
                        <div class="text-sm font-semibold text-yellow-400 mb-4">(固定网格法)</div>
                        <p class="text-gray-400 flex-grow">注意力被限制在固定的局部窗口内。高效，但不灵活且“数据无关”。</p>
                        <div class="mt-4 text-5xl">🖼️</div>
                    </div>
                     <div class="hidden md:flex items-center justify-center h-full text-5xl text-gray-600">→</div>
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6 text-center flex flex-col h-full border-2 border-teal-400">
                        <div class="text-2xl font-bold">3. 可变形注意力</div>
                        <div class="text-sm font-semibold text-teal-400 mb-4">(智能聚焦法)</div>
                        <p class="text-gray-400 flex-grow">AI学会了该看哪里，仅根据内容采样少数关键点。既高效又灵活！</p>
                        <div class="mt-4 text-5xl">🎯</div>
                    </div>
                </div>
            </section>

            <section id="breakthrough">
                 <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold">“灵光一现”的时刻</h2>
                    <p class="mt-3 text-gray-400 max-w-2xl mx-auto">突破在于让AI学会从何处采样信息，灵感来自可变形卷积。这立即带来了巨大的影响。</p>
                </div>
                <div class="grid grid-cols-1 md:grid-cols-2 gap-8">
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6">
                        <h3 class="text-xl font-bold text-center mb-4">集中计算能力</h3>
                        <p class="text-gray-400 text-center text-sm mb-4">可变形注意力不再处理数百万像素，而是聚焦于一个微小但相关的子集。</p>
                        <div class="chart-container h-64 md:h-80">
                            <canvas id="focusChart"></canvas>
                        </div>
                        <p class="text-gray-500 text-xs text-center mt-2">示例：对于每个查询，仅从一个64x64（共4096个）的特征图中采样4个关键点。</p>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6 flex flex-col items-center justify-center text-center">
                        <div class="text-7xl md:text-9xl font-black gradient-text">10x</div>
                        <h3 class="mt-4 text-2xl md:text-3xl font-bold">更快的训练速度</h3>
                        <p class="mt-2 text-gray-400">Deformable DETR的训练速度比原始DETR快10倍，同时还获得了更高的准确率。</p>
                    </div>
                </div>
            </section>

            <section id="how-it-works">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold">底层揭秘：智能聚焦如何工作</h2>
                    <p class="mt-3 text-gray-400 max-w-2xl mx-auto">这不是魔法，而是一个巧妙的多步骤过程，让AI学会了该看哪里。</p>
                </div>
                <div class="max-w-5xl mx-auto grid grid-cols-1 md:grid-cols-2 lg:grid-cols-4 gap-6">
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6 flex flex-col items-center text-center h-full">
                        <div class="text-4xl font-bold text-purple-400 mb-4">1</div>
                        <div class="text-5xl mb-4">📍</div>
                        <h4 class="text-lg font-bold mb-2">定义参考点</h4>
                        <p class="text-gray-400 text-sm flex-grow">对于每个查询（像素或物体查询），模型从一个基础位置或“参考点”开始。</p>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6 flex flex-col items-center text-center h-full">
                        <div class="text-4xl font-bold text-purple-400 mb-4">2</div>
                        <div class="text-5xl mb-4">🧠</div>
                        <h4 class="text-lg font-bold mb-2">预测偏移量</h4>
                        <p class="text-gray-400 text-sm flex-grow">一个小型神经网络根据查询内容预测一组2D偏移量。这就是“学习该看哪里”的一步。</p>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6 flex flex-col items-center text-center h-full">
                        <div class="text-4xl font-bold text-purple-400 mb-4">3</div>
                        <div class="text-5xl mb-4">🧬</div>
                        <h4 class="text-lg font-bold mb-2">采样特征</h4>
                        <p class="text-gray-400 text-sm flex-grow">模型从新位置（参考点+偏移量）采样特征，使用双线性插值以获得亚像素精度。</p>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6 flex flex-col items-center text-center h-full">
                        <div class="text-4xl font-bold text-purple-400 mb-4">4</div>
                        <div class="text-5xl mb-4">⚡️</div>
                        <h4 class="text-lg font-bold mb-2">计算注意力</h4>
                        <p class="text-gray-400 text-sm flex-grow">然后仅对这个微小但相关的采样点集计算注意力，从而实现线性复杂度。</p>
                    </div>
                </div>
            </section>

            <section id="showdown">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold">巅峰对决：DAT vs. Swin</h2>
                    <p class="mt-3 text-gray-400 max-w-2xl mx-auto">新的可变形注意力Transformer (DAT) 与前代冠军Swin Transformer进行了基准测试。结果一目了然。</p>
                </div>
                <div class="grid grid-cols-1 lg:grid-cols-3 gap-8">
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6">
                        <h3 class="text-xl font-bold text-center mb-4">ImageNet 图像分类 (准确率)</h3>
                        <div class="chart-container">
                            <canvas id="imagenetChart"></canvas>
                        </div>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6">
                        <h3 class="text-xl font-bold text-center mb-4">COCO 物体检测 (Box AP)</h3>
                        <div class="chart-container">
                            <canvas id="cocoChart"></canvas>
                        </div>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-xl p-6">
                         <h3 class="text-xl font-bold text-center mb-4">ADE20K 语义分割 (mIoU)</h3>
                        <div class="chart-container">
                            <canvas id="ade20kChart"></canvas>
                        </div>
                    </div>
                </div>
            </section>
            
            <section id="generative-leap">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold">超越识别：<span class="gradient-text">生成式的飞跃</span></h2>
                    <p class="mt-3 text-gray-400 max-w-3xl mx-auto">当DAT学习*理解*图像时，AI的另一个分支则使用类似的Transformer概念来*创造*图像。像Stable Diffusion这样的模型可以仅通过文本提示生成令人惊叹的图像。</p>
                </div>
                <div class="bg-gray-800/50 rounded-xl p-6 md:p-8">
                    <h3 class="text-2xl font-bold text-center mb-8">梦想的架构：Stable Diffusion如何工作</h3>
                    <div class="grid grid-cols-1 md:grid-cols-5 gap-y-8 md:gap-x-4 items-start text-center">
                        
                        <div class="flex flex-col items-center gap-y-4">
                            <div class="bg-gray-800 rounded-lg p-4 w-full h-full flex flex-col justify-center min-h-[200px]">
                                <div class="text-5xl">✍️</div>
                                <h4 class="font-bold mt-2">1. 提示词</h4>
                                <p class="text-sm text-gray-400">用户写下所需图像的文本描述。</p>
                            </div>
                            <div class="text-3xl text-gray-600">↓</div>
                            <div class="bg-gray-800 rounded-lg p-4 w-full h-full flex flex-col justify-center min-h-[200px]">
                                <div class="text-4xl break-all">🔡→🔢</div>
                                <h4 class="font-bold mt-2">2. 文本编码器 (CLIP)</h4>
                                <p class="text-sm text-gray-400">一个 <span class="font-bold text-teal-400">Transformer</span> 模型将文本转换为AI能理解的数字嵌入。</p>
                            </div>
                        </div>

                        <div class="hidden md:flex justify-center items-center w-full h-full">
                            <div class="text-5xl text-gray-600 mt-[-120px]">→</div>
                        </div>

                        <div class="flex flex-col items-center gap-y-4">
                            <div class="bg-gray-800 rounded-lg p-4 w-full h-full flex flex-col justify-center min-h-[200px]">
                                <div class="text-5xl">🌀</div>
                                <h4 class="font-bold mt-2">3. 潜空间扩散</h4>
                                <p class="text-sm text-gray-400">过程从一个压缩的“潜空间”中的随机噪声开始，以提高效率。</p>
                            </div>
                            <div class="text-3xl text-gray-600">↓</div>
                            <div class="bg-gray-800 rounded-lg p-4 w-full h-full flex flex-col justify-center min-h-[200px]">
                                <div class="text-5xl">🧼</div>
                                <h4 class="font-bold mt-2">4. U-Net 降噪</h4>
                                <p class="text-sm text-gray-400">在文本嵌入的引导下，一个U-Net模型通过多步迭代“清理”噪声，形成一个连贯的潜空间图像。</p>
                            </div>
                        </div>

                        <div class="hidden md:flex justify-center items-center w-full h-full">
                            <div class="text-5xl text-gray-600 mt-[-120px]">→</div>
                        </div>

                        <div class="flex flex-col items-center gap-y-4">
                            <div class="bg-gray-800 rounded-lg p-4 w-full h-full flex flex-col justify-center min-h-[200px]">
                                <div class="text-5xl">✨</div>
                                <h4 class="font-bold mt-2">5. VAE 解码器</h4>
                                <p class="text-sm text-gray-400">清晰的潜空间图像被送入一个变分自编码器（VAE）解码器。</p>
                            </div>
                            <div class="text-3xl text-gray-600">↓</div>
                            <div class="bg-gray-800 rounded-lg p-4 w-full h-full flex flex-col justify-center min-h-[200px]">
                                <div class="text-5xl">🖼️</div>
                                <h4 class="font-bold mt-2">6. 最终图像</h4>
                                <p class="text-sm text-gray-400">VAE将潜空间数据转换回像素空间，生成最终的高分辨率图像。</p>
                            </div>
                        </div>
                    </div>
                </div>
            </section>

            <section id="legacy">
                <div class="text-center mb-12">
                    <h2 class="text-3xl md:text-4xl font-bold">智能视觉的传承</h2>
                    <p class="mt-3 text-gray-400 max-w-2xl mx-auto">“学习该看哪里”以及使用Transformer进行视觉处理的核心思想非常强大，现已应用于解决许多其他领域的问题。</p>
                </div>
                <div class="grid grid-cols-2 md:grid-cols-4 gap-4 md:gap-8 text-center">
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6">
                        <div class="text-5xl mb-3">📈</div>
                        <h4 class="text-lg font-bold">时间序列</h4>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6">
                        <div class="text-5xl mb-3">🛰️</div>
                        <h4 class="text-lg font-bold">遥感技术</h4>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6">
                        <div class="text-5xl mb-3">🩺</div>
                        <h4 class="text-lg font-bold">医学影像</h4>
                    </div>
                    <div class="bg-gray-800 rounded-xl shadow-lg p-6">
                        <div class="text-5xl mb-3">🎬</div>
                        <h4 class="text-lg font-bold">视觉追踪</h4>
                    </div>
                </div>
            </section>

        </main>

        <footer class="text-center mt-16 md:mt-24 py-8 border-t border-gray-700">
            <p class="text-gray-500">从理解到创造，先进的注意力机制代表了向更高效、更智能的AI系统的范式转变。</p>
            <p class="text-sm text-gray-600 mt-2">基于研究论文“Vision Transformer with Deformable Attention” (2106.09685) 及 Stable Diffusion 架构。</p>
        </footer>

    </div>

    <script>
        document.addEventListener('DOMContentLoaded', () => {
            const palette = {
                teal: '#00F5D4',
                purple: '#9B5DE5',
                pink: '#F15BB5',
                yellow: '#FEE440',
                gray: 'rgba(209, 213, 219, 0.5)'
            };

            const sharedTooltipConfig = {
                plugins: {
                    tooltip: {
                        callbacks: {
                            title: function(tooltipItems) {
                                const item = tooltipItems[0];
                                let label = item.chart.data.labels[item.dataIndex];
                                if (Array.isArray(label)) {
                                  return label.join(' ');
                                }
                                return label;
                            }
                        }
                    }
                }
            };

            const sharedChartOptions = {
                maintainAspectRatio: false,
                responsive: true,
                scales: {
                    y: {
                        beginAtZero: true,
                        grid: { color: palette.gray },
                        ticks: { color: 'white' }
                    },
                    x: {
                        grid: { display: false },
                        ticks: { color: 'white' }
                    }
                },
                plugins: {
                    legend: {
                        labels: { color: 'white' }
                    },
                    tooltip: sharedTooltipConfig.plugins.tooltip
                }
            };

            new Chart(document.getElementById('focusChart'), {
                type: 'doughnut',
                data: {
                    labels: ['采样点', '忽略点'],
                    datasets: [{
                        data: [4, 4092],
                        backgroundColor: [palette.teal, 'rgba(255, 255, 255, 0.1)'],
                        borderColor: [palette.teal, 'rgba(255, 255, 255, 0.1)'],
                        borderWidth: 1
                    }]
                },
                options: {
                    maintainAspectRatio: false,
                    responsive: true,
                    plugins: {
                        legend: {
                            position: 'bottom',
                            labels: { color: 'white' }
                        },
                        tooltip: sharedTooltipConfig.plugins.tooltip
                    }
                }
            });

            const benchmarkLabels = ['微型模型', '小型模型', '基础模型'];
            const swinColor = palette.pink;
            const datColor = palette.teal;

            new Chart(document.getElementById('imagenetChart'), {
                type: 'bar',
                data: {
                    labels: benchmarkLabels,
                    datasets: [
                        {
                            label: 'Swin',
                            data: [81.3, 83.0, 83.3],
                            backgroundColor: swinColor,
                        },
                        {
                            label: 'DAT',
                            data: [82.0, 83.6, 84.0],
                            backgroundColor: datColor,
                        }
                    ]
                },
                options: { ...sharedChartOptions, scales: { ...sharedChartOptions.scales, y: { ...sharedChartOptions.scales.y, min: 80 } } }
            });

            new Chart(document.getElementById('cocoChart'), {
                type: 'bar',
                data: {
                    labels: benchmarkLabels,
                    datasets: [
                        {
                            label: 'Swin',
                            data: [46.0, 48.5, 49.5],
                            backgroundColor: swinColor,
                        },
                        {
                            label: 'DAT',
                            data: [47.1, 49.4, 50.1],
                            backgroundColor: datColor,
                        }
                    ]
                },
                options: { ...sharedChartOptions, scales: { ...sharedChartOptions.scales, y: { ...sharedChartOptions.scales.y, min: 45 } } }
            });

            new Chart(document.getElementById('ade20kChart'), {
                type: 'bar',
                data: {
                    labels: benchmarkLabels,
                    datasets: [
                        {
                            label: 'Swin',
                            data: [47.6, 49.5, 49.7],
                            backgroundColor: swinColor,
                        },
                        {
                            label: 'DAT',
                            data: [48.6, 50.4, 50.9],
                            backgroundColor: datColor,
                        }
                    ]
                },
                options: { ...sharedChartOptions, scales: { ...sharedChartOptions.scales, y: { ...sharedChartOptions.scales.y, min: 47 } } }
            });
        });
    </script>

</body>
</html>
